{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88056f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5491ba",
   "metadata": {},
   "source": [
    "# Scrape the Data\n",
    "Obtain all of the match scores for the European Champions League water polo tournaments for the current season (2022-2023) from flashscore.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5172385",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.flashscore.com/water-polo/europe/champions-league/results/'\n",
    "\n",
    "# xpath for the \"Show more matches\" link often initially at the bottom of the table, hiding some of the match sores\n",
    "show_more_xpath = '/html/body/div[3]/div[1]/div/div/main/div[4]/div[2]/div[1]/div[1]/div/div/a'\n",
    "\n",
    "\n",
    "driver = webdriver.Firefox()\n",
    "driver.get(url)\n",
    "    \n",
    "# many (but not all) pages have matches that are hidden by a \"Show more matches\" header\n",
    "# this section clicks the header, if it is there\n",
    "try:\n",
    "    element = driver.find_element(\"xpath\", show_more_xpath)\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView();\", element)\n",
    "    element.click()\n",
    "    time.sleep(10) # waits for 10 seconds for the page to load/update from the click()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "sauce = driver.page_source\n",
    "driver.quit()\n",
    "soup = BeautifulSoup(sauce,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be5eb2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to determine if the tag is part of the data targeted for extraction\n",
    "def target_tags(c):\n",
    "    target_class = [\"event__header\",\n",
    "                    \"event__round\",\n",
    "                    \"event__match\"]\n",
    "    return c in target_class\n",
    "    \n",
    "    \n",
    "games = soup.find_all(class_=target_tags)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "l = []\n",
    "obj = {}\n",
    "event_round = None\n",
    "event_name = None\n",
    "season = soup.find(\"div\", {\"class\": \"heading__info\"}).text\n",
    "\n",
    "\n",
    "for a in range(0, len(games)):\n",
    "\n",
    "    if games[a]['class'][0] == 'event__round':\n",
    "        event_round = games[a].text\n",
    "    if games[a]['class'][0] == 'event__header':\n",
    "        event_name = games[a].find(\"span\", {\"class\": \"event__title--name\"}).text\n",
    "        event_round = None\n",
    "        \n",
    "    obj[\"event_name\"] = event_name\n",
    "    obj[\"event_round\"] = event_round\n",
    "    \n",
    "    try:\n",
    "        obj[\"match_time\"] = games[a].find(\"div\", {\"class\": \"event__time\"}).text\n",
    "    except: \n",
    "        obj[\"match_time\"] = None\n",
    "    try:\n",
    "        obj[\"home_team\"] = games[a].find(\"div\", {\"class\": re.compile(\"^(event__participant event__participant--home)\")}).text\n",
    "    except:\n",
    "        obj[\"home_team\"] = None\n",
    "    try:\n",
    "        obj[\"away_team\"] = games[a].find(\"div\", {\"class\": re.compile(\"^(event__participant event__participant--away)\")}).text\n",
    "    except:\n",
    "        obj[\"away_team\"] = None\n",
    "    try:\n",
    "        obj[\"home_score\"] = games[a].find(\"div\", {\"class\": \"event__score event__score--home\"}).text\n",
    "    except:\n",
    "        obj[\"home_score\"] = None\n",
    "    try:\n",
    "        obj[\"away_score\"] = games[a].find(\"div\", {\"class\": \"event__score event__score--away\"}).text\n",
    "    except:\n",
    "        obj[\"away_score\"] = None\n",
    "        \n",
    "    if pd.notna(obj[\"home_team\"]):\n",
    "        l.append(obj)\n",
    "    obj = {}\n",
    "    \n",
    "    \n",
    "# Loop through and append list to data frame.\n",
    "for i in l:\n",
    "    event_name = i[\"event_name\"]\n",
    "    event_round = i[\"event_round\"]\n",
    "    match_time = i[\"match_time\"]\n",
    "    home_team = i[\"home_team\"]\n",
    "    away_team = i[\"away_team\"]\n",
    "    home_score = i[\"home_score\"]\n",
    "    away_score = i[\"away_score\"]\n",
    "    \n",
    "    df = df.append(\n",
    "        {\"event_name\": event_name,\n",
    "         \"event_round\": event_round,\n",
    "         \"match_time\": match_time,\n",
    "         \"home_team\": home_team,\n",
    "         \"away_team\": away_team,\n",
    "         \"home_score\": home_score,\n",
    "         \"away_score\": away_score,\n",
    "         \"season\": season\n",
    "        }, ignore_index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c3a2e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data from previous seasons and append with updated current season data\n",
    "df_old = pd.read_csv('champions_league_rawData_completedSeasons.csv')\n",
    "df_old = df_old.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ef5c95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the combined data by exporting to a cvs file\n",
    "df_old.to_csv('champions_league_rawData.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
